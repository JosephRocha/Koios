{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction(x1, y1, x2, y2):\n",
    "    \n",
    "    deg = math.degrees(np.arctan2(x2-x1,y2-y1))\n",
    "    \n",
    "    if(np.arctan2(x2-x1,y2-y1) < 0):\n",
    "        deg+=360\n",
    "    \n",
    "    if(deg >= 22.5 and deg < 67.5):\n",
    "        return 2\n",
    "    elif(deg >= 67.5 and deg < 112.5):\n",
    "        return 3\n",
    "    elif(deg >= 112.5 and deg < 157.5):\n",
    "        return 4\n",
    "    elif(deg >= 157.5 and deg < 202.5):\n",
    "        return 5\n",
    "    elif(deg >= 202.5 and deg < 247.5):\n",
    "        return 6\n",
    "    elif(deg >= 247.5 and deg < 292.5):\n",
    "        return 7\n",
    "    elif(deg >= 292.5 and deg < 337.5):\n",
    "        return 8\n",
    "    elif(deg >= 337.5 or deg < 22.5):\n",
    "        return 1\n",
    "\n",
    "def ProcessRawData(df):\n",
    "    df['stroke'] = list(pd.qcut(df['timestamp'], len(df)//30, labels=np.arange(0, len(df)//30)))\n",
    "    \n",
    "    distX = df.loc[:, 'x'].diff()\n",
    "    distX[0] = 0\n",
    "    distY = df.loc[:, 'y'].diff()\n",
    "    distY[0] = 0\n",
    "    distTime = df.loc[:, 'timestamp'].diff()\n",
    "    distTime[0] = 0\n",
    "    df['distance'] = np.sqrt(np.square(distX) + np.square(distY))\n",
    "    df['velocity'] = df['distance']/distTime\n",
    "    df.loc[0, 'velocity'] = 0\n",
    "    \n",
    "    velocityList = ['Velocity_Total', 'Velocity_Min', 'Velocity_Max', 'Velocity_STD', 'Velocity_Mean', 'Velocity_Median']\n",
    "    columns = velocityList\n",
    "    TrainingData = pd.DataFrame(columns=columns, index=list(np.arange(1, 9)))\n",
    "    \n",
    "    df['direction'] = -1\n",
    "    for x in df['stroke'].unique():\n",
    "        direction = get_direction(int(df[df['stroke'] == x].head(1)['x']),\n",
    "            int(df[df['stroke'] == x].head(1)['y']),\n",
    "            int(df[df['stroke'] == x].tail(1)['x']),\n",
    "            int(df[df['stroke'] == x].tail(1)['y'])\n",
    "           )\n",
    "        df.loc[df['stroke'] == x, 'direction'] = direction\n",
    "    \n",
    "    timeStampKeyList = []\n",
    "    for x in range(0, len(df)):\n",
    "        if(x == 0):\n",
    "            continue\n",
    "        if(df.loc[x, 'keyDown'] == 1 and df.loc[x-1, 'keyDown'] == 1):\n",
    "            timeStampKeyList.append(df.loc[x, 'timestamp'] - df.loc[x-1, 'timestamp'])\n",
    "    timeStampKeyList = np.array(timeStampKeyList)\n",
    "    \n",
    "    timeStampClickList = []\n",
    "    for x in range(0, len(df)):\n",
    "        \n",
    "        if(df.loc[x, 'mouseDown'] == 256):\n",
    "            timeStampClickList.append(df.loc[x, 'timestamp'] - df.loc[x-1, 'timestamp'])\n",
    "    timeStampClickList = np.array(timeStampClickList)\n",
    "    \n",
    "    \n",
    "    for x in df['direction'].unique():\n",
    "        TrainingData.loc[x, 'Velocity_Total'] = df[df['direction'] == x]['velocity'].sum()\n",
    "        TrainingData.loc[x, 'Velocity_Min'] = df[df['direction'] == x]['velocity'].min()\n",
    "        TrainingData.loc[x, 'Velocity_Max'] = df[df['direction'] == x]['velocity'].max()\n",
    "        TrainingData.loc[x, 'Velocity_STD'] = df[df['direction'] == x]['velocity'].std()\n",
    "        TrainingData.loc[x, 'Velocity_Mean'] = df[df['direction'] == x]['velocity'].mean()\n",
    "        TrainingData.loc[x, 'Velocity_Median'] = df[df['direction'] == x]['velocity'].median()\n",
    "    \n",
    "    X = np.array(TrainingData).flatten()\n",
    "    \n",
    "    MouseData = np.array([timeStampClickList.sum(),\n",
    "                     timeStampClickList.min(),\n",
    "                     timeStampClickList.max(),\n",
    "                     timeStampClickList.std(),\n",
    "                     timeStampClickList.mean(),\n",
    "                     np.median(timeStampClickList)])\n",
    "\n",
    "    KeyboardData = np.array([timeStampKeyList.sum(),\n",
    "                     timeStampKeyList.min(),\n",
    "                     timeStampKeyList.max(),\n",
    "                     timeStampKeyList.std(),\n",
    "                     timeStampKeyList.mean(),\n",
    "                     np.median(timeStampKeyList)])\n",
    "    \n",
    "    result = np.concatenate((X, MouseData, KeyboardData))\n",
    "    \n",
    "    #Normalize Result\n",
    "    return(result)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/JAR60')\n",
    "df['group'] = pd.cut(x=df['timestamp'], bins=6, labels=list(np.arange(0, 6)))\n",
    "\n",
    "JosephIntervals = []\n",
    "\n",
    "for x in df['group'].unique():\n",
    "    clone = df.loc[df['group'] == x, :].copy()\n",
    "    clone = clone.drop('group', axis=1).reset_index()\n",
    "    JosephIntervals.append(ProcessRawData(clone))\n",
    "    \n",
    "df = pd.read_csv('../datasets/CSJ30')\n",
    "df['group'] = pd.cut(x=df['timestamp'], bins=6, labels=list(np.arange(0, 6)))\n",
    "\n",
    "ChristiansIntervals = []\n",
    "\n",
    "for x in df['group'].unique():\n",
    "    clone = df.loc[df['group'] == x, :].copy()\n",
    "    clone = clone.drop('group', axis=1).reset_index()\n",
    "    ChristiansIntervals.append(ProcessRawData(clone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[710.1196305489541, 0.0, 4.428571428571429, 0.5727975339506444,\n",
       "        0.37712141824161133, 0.13975424859373686, 1986.4516071188834,\n",
       "        0.0, 6.437735971942655, 1.2249356908297218, 0.9912433169255905,\n",
       "        0.5, 6645.825919261314, 0.0, 62.80127387243033,\n",
       "        1.6480324838916023, 1.1852730371430915, 0.625,\n",
       "        2151.6553553641347, 0.0, 10.73312629199899, 1.4039563314331143,\n",
       "        1.0096927993262013, 0.5150787536377127, 1064.3858166537034, 0.0,\n",
       "        4.989785484735137, 0.6973654726442403, 0.60100836626409, 0.375,\n",
       "        2442.699014664565, 0.0, 22.14158982548453, 1.44349918155564,\n",
       "        1.0713592169581425, 0.5590169943749475, 5466.967420698568, 0.0,\n",
       "        32.2490309931942, 1.2676920837870467, 1.0713242055062842, 0.625,\n",
       "        3292.3343773641877, 0.0, 12.40071682515885, 1.3544899351168793,\n",
       "        1.154799851758747, 0.6388765649999399, 26181.0, 1.0, 1440.0,\n",
       "        107.51004940348098, 48.84514925373134, 8.0, 140497.0, 16.0,\n",
       "        1753.0, 132.10055350158805, 166.26863905325445, 135.0],\n",
       "       [761.6801475618281, 0.0, 4.47213595499958, 0.7382881685258618,\n",
       "        0.3842987626447165, 0.005910654547472363, 1714.2293468547568,\n",
       "        0.0, 9.231711097944864, 1.2348813502234162, 1.0575134773934343,\n",
       "        0.6009252125773316, 7348.314201257133, 0.0, 11.333333333333334,\n",
       "        1.3390936108845344, 1.1995289260948634, 0.75, 1770.1569933194912,\n",
       "        0.0, 19.697715603592208, 1.2876638042327506, 1.0536648769758876,\n",
       "        0.5429428207227331, 1111.5969454678911, 0.0, 5.55090082779363,\n",
       "        0.8869416931704283, 0.7116497730268189, 0.375,\n",
       "        2227.2172856076995, 0.0, 14.379769740081995, 1.4741586678309118,\n",
       "        1.0743932877991798, 0.5303300858899106, 6592.397533085358, 0.0,\n",
       "        11.0, 1.4225286139479252, 1.2540227378895488, 0.7211102550927978,\n",
       "        2033.7137846077285, 0.0, 10.540925533894598, 1.3052073533424513,\n",
       "        1.0760390394749886, 0.5555555555555556, 29713.0, 3.0, 1200.0,\n",
       "        104.9570633960878, 45.782742681047765, 8.0, 177779.0, 29.0,\n",
       "        1408.0, 126.39479867980718, 171.60135135135135, 131.0],\n",
       "       [1003.6093962993411, 0.0, 5.8576872569299905, 0.6813084201181591,\n",
       "        0.42346388029508064, 0.125, 3110.0892592697655, 0.0,\n",
       "        22.80350850198276, 1.4731524868945776, 1.3122739490589728,\n",
       "        0.832993127835043, 5999.370821996454, 0.0, 12.041594578792296,\n",
       "        1.2880599088181062, 1.0002285465149139, 0.5, 1326.2368182377922,\n",
       "        0.0, 7.879086241436883, 0.8936373615474771, 0.7894266775224954,\n",
       "        0.5, 1730.5152279524211, 0.0, 5.727128425310541,\n",
       "        0.9105686225424767, 0.8240548704535339, 0.5, 2559.2837105431436,\n",
       "        0.0, 13.148721948877347, 1.3690125473315253, 1.107915026209153,\n",
       "        0.5890150893739515, 6023.3577322561105, 0.0, 12.0,\n",
       "        1.3698341024298268, 1.1607935502517075, 0.673145600891813,\n",
       "        1901.5218013023011, 0.0, 10.957303500405564, 1.451713454576877,\n",
       "        1.24282470673353, 0.7476779962499649, 67518.0, 2.0, 2986.0,\n",
       "        184.84497032778032, 109.07592891760905, 40.0, 141978.0, 8.0,\n",
       "        818.0, 103.19248949699313, 156.8817679558011, 128.0],\n",
       "       [1018.0481312621083, 0.0, 4.669047011971501, 0.6749681868901092,\n",
       "        0.45266702145936344, 0.1767766952966369, 1668.6012318046014, 0.0,\n",
       "        17.204650534085253, 1.3207212689807704, 1.0689309620785403, 0.5,\n",
       "        5863.2200783065355, 0.0, 25.0, 1.613986384721443,\n",
       "        1.2131636826622254, 0.5983516452371671, 1932.6751815919401, 0.0,\n",
       "        8.65383665716478, 1.142713558011216, 0.9056584730983787,\n",
       "        0.5150787536377127, 1581.4539596062266, 0.0, 9.737171047075224,\n",
       "        0.9266402745161737, 0.6755463304597294, 0.375,\n",
       "        1586.5879609544113, 0.0, 7.826237921249264, 1.059593100030726,\n",
       "        0.9272869438658161, 0.5665577237325317, 5500.6170789813, 0.0,\n",
       "        38.3275357934736, 1.5706318347069652, 1.138608379006686, 0.625,\n",
       "        2386.424219258664, 0.0, 24.413111231467404, 1.4009614354757811,\n",
       "        1.1022744661702835, 0.5714285714285714, 130832.0, 6.0, 2344.0,\n",
       "        216.7004105724755, 200.04892966360856, 121.0, 106741.0, 24.0,\n",
       "        1161.0, 121.7159208127138, 171.60932475884243, 129.0],\n",
       "       [750.4175723371161, 0.0, 7.607729688968199, 0.6028387861558152,\n",
       "        0.32471552243059976, 0.004016064257028112, 1797.5984587268981,\n",
       "        0.0, 8.171628369185767, 1.1023426926426443, 0.9199582695634074,\n",
       "        0.5153882032022076, 5577.205240009283, 0.0, 17.0,\n",
       "        1.0826196092547977, 0.9105641208178422, 0.5890150893739515,\n",
       "        1824.6570011337908, 0.0, 9.433981132056603, 1.0896414116160655,\n",
       "        0.8935636636306518, 0.45069390943299864, 1120.8169102384045, 0.0,\n",
       "        4.138236339311712, 0.6108412336980217, 0.6219849668359625,\n",
       "        0.45069390943299864, 1804.7737624172546, 0.0, 6.485560885536423,\n",
       "        0.9263598761986828, 0.8718713828102679, 0.5590169943749475,\n",
       "        5174.854926563241, 0.0, 19.235384061671343, 1.077257287662229,\n",
       "        0.9736321592781262, 0.625, 2540.639066442998, 0.0, 14.0,\n",
       "        1.1698207297167629, 0.972307335033677, 0.5590169943749475,\n",
       "        36299.0, 7.0, 1273.0, 161.43810308856408, 165.74885844748857,\n",
       "        112.0, 185890.0, 17.0, 1335.0, 113.13433272033568,\n",
       "        161.64347826086956, 135.0],\n",
       "       [1231.4572317692023, 0.0, 9.013878188659973, 0.7682256383949427,\n",
       "        0.3993051983687426, 0.0, 1817.7060902750188, 0.0, 5.0,\n",
       "        0.956236086339872, 0.9932820165437262, 0.6758625033664688,\n",
       "        5890.431648154826, 0.0, 50.0, 1.7250803677863384,\n",
       "        1.1692004065412516, 0.6373774391990981, 1563.3257271573825, 0.0,\n",
       "        12.14578116055118, 1.0083652777074743, 0.8414024365755557,\n",
       "        0.5303300858899106, 1365.012859089185, 0.0, 5.618051263561058,\n",
       "        0.6645677397247951, 0.6691239505339142, 0.45175395145262565,\n",
       "        2208.498958879114, 0.0, 8.077747210701755, 1.023740331004947,\n",
       "        0.9088473081807054, 0.5303300858899106, 5334.167203144383, 0.0,\n",
       "        23.0, 1.3433300717624472, 1.2347609266537924, 0.7905694150420949,\n",
       "        1561.0608913588126, 0.0, 14.317821063276353, 0.9680556361793209,\n",
       "        0.9129011060577852, 0.628539361054709, 35016.0, 6.0, 630.0,\n",
       "        125.54612056068773, 105.78851963746223, 66.0, 276947.0, 15.0,\n",
       "        1016.0, 105.3591377976152, 161.67367192060712, 129.0],\n",
       "       [1397.8397296494763, 0.0, 10.241970473677098, 1.031705091632228,\n",
       "        0.42397322706990487, 0.0, 946.9225997138153, 0.0,\n",
       "        10.295630140987, 1.283749624424781, 1.0884167812802474,\n",
       "        0.616638126514911, 1084.5064503078943, 0.0, 14.560219778561036,\n",
       "        1.3676761384108853, 0.9787964352959335, 0.4444444444444444,\n",
       "        1041.4841820839301, 0.0, 6.010407640085654, 1.1003712146657652,\n",
       "        0.8686273411875981, 0.42857142857142855, 1431.8530486190905, 0.0,\n",
       "        9.06228448019593, 1.6720428512257202, 1.403777498646167,\n",
       "        0.7930323654987461, 900.7869451384933, 0.0, 19.4164878389476,\n",
       "        1.7687916551494822, 1.2510929793590184, 0.5590169943749475,\n",
       "        1281.2835031205655, 0.0, 12.5, 1.277315023695279,\n",
       "        0.9483963753668138, 0.5665577237325317, 844.9740467521352, 0.0,\n",
       "        8.066053836281773, 1.4819278199723689, 1.1281362439948401, 0.5,\n",
       "        8504.0, 7.0, 673.0, 89.17987635796666, 44.291666666666664, 8.0,\n",
       "        392536.0, 25.0, 2088.0, 139.4725256722061, 173.84233835252437,\n",
       "        136.0],\n",
       "       [1668.2982232697068, 0.0, 10.666666666666666, 1.1166129081827185,\n",
       "        0.6192643738937293, 0.13654379096353508, 1317.8803233501367, 0.0,\n",
       "        18.867962264113206, 1.3893150106679102, 0.9536037071998095,\n",
       "        0.45175395145262565, 3039.2671337033844, 0.0, 16.0,\n",
       "        1.3715081769061868, 0.9459281461884171, 0.42857142857142855,\n",
       "        2015.1703224211285, 0.0, 34.0, 1.7380002818159637,\n",
       "        1.0834249045274884, 0.45069390943299864, 1856.147289890886, 0.0,\n",
       "        15.890248582070704, 1.8224930323920552, 1.2626852312182897, 0.5,\n",
       "        1013.4855466975226, 0.0, 13.756816492197604, 1.3775260231352058,\n",
       "        0.9375444465286981, 0.39528470752104744, 3417.7811208068, 0.0,\n",
       "        27.29981684920249, 1.6806209441650488, 1.0751120229024222,\n",
       "        0.4969039949999533, 1769.2219786951364, 0.0, 12.23837316712388,\n",
       "        1.249612581317524, 1.0537355441900753, 0.6060915267313264,\n",
       "        45421.0, 2.0, 1304.0, 74.46348737849999, 25.69061085972851, 8.0,\n",
       "        259351.0, 31.0, 2697.0, 241.10323986606014, 218.4928390901432,\n",
       "        144.0],\n",
       "       [1618.9268159536182, 0.0, 9.633275663033837, 1.1191089606454814,\n",
       "        0.8054362268425961, 0.375, 1322.0943263521544, 0.0,\n",
       "        9.803627446568495, 1.1140521795973517, 0.7465241820170267,\n",
       "        0.35136418446315326, 3162.226438294625, 0.0, 14.5152980524349,\n",
       "        1.4446987036640797, 0.9009192131893519, 0.375, 914.0437180875426,\n",
       "        0.0, 9.341590128155323, 1.0167934025402066, 0.634752582005238,\n",
       "        0.2795084971874737, 1327.009749929393, 0.0, 6.946221994724902,\n",
       "        1.1168139176012306, 0.8846731666195953, 0.39528470752104744,\n",
       "        1566.4923790621774, 0.0, 10.062305898749054, 1.2347373407116373,\n",
       "        0.9160774146562441, 0.45069390943299864, 3110.617835079373, 0.0,\n",
       "        15.532224567009067, 1.495147726345948, 0.91785713634682,\n",
       "        0.39528470752104744, 1057.1327308905784, 0.0, 8.353309390761112,\n",
       "        1.0826840089596363, 0.7654835125927432, 0.375, 46433.0, 2.0,\n",
       "        4248.0, 144.99592069859102, 32.5617110799439, 8.0, 41419.0, 16.0,\n",
       "        1648.0, 238.40960717565636, 197.23333333333332, 121.0],\n",
       "       [1962.8494420975815, 0.0, 17.08800749063506, 1.150236255687575,\n",
       "        0.7785995406971763, 0.375, 1691.3691986599358, 0.0,\n",
       "        9.067647005823629, 1.03017524795579, 0.7228073498546734, 0.375,\n",
       "        2340.7533283551356, 0.0, 15.0, 1.182605276180861,\n",
       "        0.7961746014813387, 0.39528470752104744, 1616.6510881501968, 0.0,\n",
       "        10.749676997731399, 1.170579217808473, 0.8043040239553217,\n",
       "        0.3535533905932738, 2315.407883915888, 0.0, 9.86470982847443,\n",
       "        1.4914371508108468, 1.151371399262003, 0.4969039949999533,\n",
       "        1466.5955756436144, 0.0, 14.136477637657833, 1.113291060208019,\n",
       "        0.7521002952018535, 0.3535533905932738, 2532.7535183892805, 0.0,\n",
       "        16.0312195418814, 1.393287831684113, 0.879428304996278, 0.375,\n",
       "        1683.106792456816, 0.0, 9.285592184789413, 0.9404223811466776,\n",
       "        0.7905621383075697, 0.45069390943299864, 43123.0, 2.0, 1768.0,\n",
       "        77.27183320644065, 25.745074626865673, 8.0, 112203.0, 12.0,\n",
       "        7097.0, 517.4386908128104, 289.93023255813955, 136.0],\n",
       "       [1321.9407012272277, 0.0, 6.343886660335577, 0.9240915544925491,\n",
       "        0.7344115006817932, 0.4040610178208843, 1758.6880600260151, 0.0,\n",
       "        28.85211334450987, 1.3249241127150457, 0.8604149021653694,\n",
       "        0.39528470752104744, 3939.1630217105885, 0.0, 13.597385369580758,\n",
       "        1.3435775128087344, 0.994989396744276, 0.4581228472908512,\n",
       "        1820.2502976099245, 0.0, 6.880911187881312, 1.2389142116925869,\n",
       "        0.9174648677469377, 0.39528470752104744, 1796.729893107932, 0.0,\n",
       "        11.764352935882194, 1.1521446013481542, 0.8658939243893647,\n",
       "        0.40061680838488767, 1218.7164151582297, 0.0, 10.176225014982498,\n",
       "        1.3640965410153014, 0.845743521969625, 0.3333333333333333,\n",
       "        4062.895140233897, 0.0, 32.31098884280702, 1.5981423486587685,\n",
       "        1.0484890684474573, 0.4444444444444444, 2010.5182432361385, 0.0,\n",
       "        16.97056274847714, 1.791454570832041, 1.1946038284231364,\n",
       "        0.5555555555555556, 43592.0, 1.0, 4032.0, 151.5959367392549,\n",
       "        33.92373540856031, 8.0, 62603.0, 19.0, 3592.0, 319.5338293482042,\n",
       "        243.59143968871595, 150.0],\n",
       "       [1472.2198046023282, 0.0, 12.36931687685298, 0.8864012272974424,\n",
       "        0.4589213854745412, 0.058823529411764705, 1439.5127604551424,\n",
       "        0.0, 11.385633625812158, 1.415386248996486, 0.9989679114886484,\n",
       "        0.42857142857142855, 3416.7757681864605, 0.0, 16.944085717923127,\n",
       "        1.8436873285579072, 1.1154997610794843, 0.5, 1645.9037321928513,\n",
       "        0.0, 21.644860821913362, 1.6684701327798779, 1.0980011555656113,\n",
       "        0.45069390943299864, 1616.6741350830057, 0.0, 10.593499054713803,\n",
       "        1.1530747295498653, 0.8544789297478889, 0.41231056256176607,\n",
       "        1315.937056264332, 0.0, 25.553864678361276, 1.8976315250824822,\n",
       "        1.020106245166149, 0.4040610178208843, 4024.5116673764046, 0.0,\n",
       "        19.428571428571427, 1.8479053387376678, 1.288668481388538,\n",
       "        0.5665577237325317, 1350.4618466165202, 0.0, 11.64283279771532,\n",
       "        1.4731056992643463, 1.0979364606638375, 0.5150787536377127,\n",
       "        42773.0, 2.0, 1137.0, 59.63020288939988, 21.86758691206544, 8.0,\n",
       "        252428.0, 15.0, 992.0, 107.08976626102773, 157.47223955084218,\n",
       "        128.0]], dtype=object)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array((JosephIntervals[0], JosephIntervals[1], JosephIntervals[2], JosephIntervals[3], JosephIntervals[4],JosephIntervals[5],\n",
    "                    ChristiansIntervals[0], ChristiansIntervals[1], ChristiansIntervals[2], ChristiansIntervals[3], ChristiansIntervals[4], ChristiansIntervals[5]))\n",
    "y_train = np.array([[1, 0], [1, 0], [1, 0], [1, 0], [1,0], [1,0], [0, 1], [0,1] , [0,1], [0,1], [0, 1], [0, 1]])\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=60))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9 samples, validate on 3 samples\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 4s 447ms/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 535us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 588us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 986us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 698us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 655us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 929us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 549us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 793us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 726us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 536us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 657us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 733us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 502us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 522us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 373us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 480us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 658us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 406us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 719us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 601us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 717us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 609us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 655us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 668us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 608us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 372us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 367us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 444us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 561us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 441us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 838us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 690us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 619us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 479us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 478us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 758us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 458us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 511us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 516us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 888us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 771us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 702us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 436us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 431us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 462us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 781us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 543us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 543us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 604us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 555us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 967us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 592us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 498us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 606us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 650us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 805us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 628us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 477us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 425us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 552us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 765us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 510us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 466us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 662us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 409us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 477us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 546us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 507us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 374us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 520us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 481us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 615us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 428us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 732us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 694us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 719us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 463us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 487us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 694us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 381us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 525us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 958us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 552us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 405us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 416us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 415us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 413us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 637us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 799us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 775us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 739us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 529us/step - loss: 7.1246 - acc: 0.5556 - val_loss: 1.0960e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1e747e080>"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "#Train our model for 100 iteration of the training data\n",
    "model.fit(x_train, y_train, epochs=100, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('Koios.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "josephTest = pd.read_csv('../datasets/JosephReal5B')\n",
    "model.predict(JosephIntervals[4].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
